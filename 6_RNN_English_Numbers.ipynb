{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting English word version of numbers using an RNN\n",
    "\n",
    "To begin learning about **Recurrent Neural Networks** we will build an RNN to predict the English word version of numbers. \n",
    "\n",
    "Let's predict what should come next in this sequence: \n",
    "*eight thousand one, eight thousand two, eight thousand three, eight thousand four, ...* \n",
    "\n",
    "### In deep learning, there are 2 types of numbers\n",
    "**Parameters** are numbers that are learned. **Activations** are numbers that are calculated (by affine functions & element-wise non-linearities).\n",
    "\n",
    "When you learn about any new concept in deep learning, ask yourself: is this a parameter or an activation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "GeForce RTX 2070 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "# Making sure our GPU is setup\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "device = torch.cuda.current_device()\n",
    "\n",
    "# printing device name\n",
    "print(torch.cuda.get_device_name(device))\n",
    "\n",
    "# setting the device\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/dmber/.fastai/data/human_numbers/train.txt'),\n",
       " WindowsPath('C:/Users/dmber/.fastai/data/human_numbers/valid.txt')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.HUMAN_NUMBERS)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readnums(d): return [', '.join(o.strip() for o in open(path/d).readlines())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirt'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking our train and text\n",
    "train_text = readnums('train.txt')\n",
    "train_text[0][:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' nine thousand nine hundred ninety eight, nine thousand nine hundred ninety nine'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking our test text\n",
    "valid_text = readnums('valid.txt')\n",
    "valid_text[0][-80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our datasets with FASTAI\n",
    "train = TextList(train_text, path=path)\n",
    "valid = TextList(valid_text, path=path)\n",
    "\n",
    "src = ItemLists(path=path, train=train, valid=valid).label_for_lm()\n",
    "data = src.databunch(bs=int(bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.text.data.LMTextList"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mLMTextList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mitems\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIterator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvocab\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfastai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpad_idx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m      Special `TextList` for a language model.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\dmber\\anaconda3\\lib\\site-packages\\fastai\\text\\data.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?LMTextList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.data_block.LabelLists"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mLabelLists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpath\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtrain\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfastai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_block\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mItemList\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvalid\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfastai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_block\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mItemList\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m      A `LabelList` for each of `train` and `valid` (optional `test`).\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\dmber\\anaconda3\\lib\\site-packages\\fastai\\data_block.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?LabelLists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.text.data.TextLMDataBunch"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mTextLMDataBunch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtrain_dl\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvalid_dl\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfix_dl\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtest_dl\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdl_tfms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCollection\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpath\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcollate_fn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mCallable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mfunction\u001b[0m \u001b[0mdata_collate\u001b[0m \u001b[0mat\u001b[0m \u001b[1;36m0x00000207BDE9DF28\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mno_check\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m      Create a `TextDataBunch` suitable for training a language model.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\dmber\\anaconda3\\lib\\site-packages\\fastai\\text\\data.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?TextLMDataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13017"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length of our tokens in our valid set\n",
    "len(data.valid_ds[0][0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 19, 11, 12, ..., 20, 10, 28, 20], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.valid_ds[0][0].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bptt``` stands for *back-propogation through time*. This tells us hwo many steps of history we are considering.\n",
    "\n",
    "this can be considered the lenght of a sequence which in our case is a line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.bptt, len(data.valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 3 batches in our validation set:\n",
    "\n",
    "13017 tokens, with about ~70 tokens in about a line of text, and 64 lines of text per batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.905580357142857"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13017/70/bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will store each batch in a seperate variable, so we can walk through this to understand better what the RNN does at each step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(data.valid_dl)\n",
    "x1,y1 = next(it)\n",
    "x2,y2 = next(it)\n",
    "x3,y3 = next(it)\n",
    "it.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 70])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking the shape confirms that we have 64 rows and 70 columns per batch. this essentially represents 64 lines with 70 tokens in each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing out vocab - valid\n",
    "v = data.valid_ds.vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " ',']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'xxunk': 0,\n",
       "             'xxpad': 1,\n",
       "             'xxbos': 2,\n",
       "             'xxeos': 3,\n",
       "             'xxfld': 4,\n",
       "             'xxmaj': 5,\n",
       "             'xxup': 6,\n",
       "             'xxrep': 7,\n",
       "             'xxwrep': 8,\n",
       "             ',': 9,\n",
       "             'hundred': 10,\n",
       "             'thousand': 11,\n",
       "             'one': 12,\n",
       "             'two': 13,\n",
       "             'three': 14,\n",
       "             'four': 15,\n",
       "             'five': 16,\n",
       "             'six': 17,\n",
       "             'seven': 18,\n",
       "             'eight': 19,\n",
       "             'nine': 20,\n",
       "             'twenty': 21,\n",
       "             'thirty': 22,\n",
       "             'forty': 23,\n",
       "             'fifty': 24,\n",
       "             'sixty': 25,\n",
       "             'seventy': 26,\n",
       "             'eighty': 27,\n",
       "             'ninety': 28,\n",
       "             'ten': 29,\n",
       "             'eleven': 30,\n",
       "             'twelve': 31,\n",
       "             'thirteen': 32,\n",
       "             'fourteen': 33,\n",
       "             'fifteen': 34,\n",
       "             'sixteen': 35,\n",
       "             'seventeen': 36,\n",
       "             'eighteen': 37,\n",
       "             'nineteen': 38,\n",
       "             'xxfake': 39})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos eight thousand one , eight thousand two , eight thousand three , eight thousand four , eight thousand five , eight thousand six , eight thousand seven , eight thousand eight , eight thousand nine , eight thousand ten , eight thousand eleven , eight thousand twelve , eight thousand thirteen , eight thousand fourteen , eight thousand fifteen , eight thousand sixteen , eight thousand seventeen , eight'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the first batch - first example\n",
    "v.textify(x1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eight thousand one , eight thousand two , eight thousand three , eight thousand four , eight thousand five , eight thousand six , eight thousand seven , eight thousand eight , eight thousand nine , eight thousand ten , eight thousand eleven , eight thousand twelve , eight thousand thirteen , eight thousand fourteen , eight thousand fifteen , eight thousand sixteen , eight thousand seventeen , eight thousand'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.textify(y1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>thousand forty seven , eight thousand forty eight , eight thousand forty nine , eight thousand fifty , eight thousand fifty one , eight thousand fifty two , eight thousand fifty three , eight thousand fifty four , eight thousand fifty five , eight thousand fifty six , eight thousand fifty seven , eight thousand fifty eight , eight thousand fifty nine , eight thousand sixty , eight thousand sixty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>eight , eight thousand eighty nine , eight thousand ninety , eight thousand ninety one , eight thousand ninety two , eight thousand ninety three , eight thousand ninety four , eight thousand ninety five , eight thousand ninety six , eight thousand ninety seven , eight thousand ninety eight , eight thousand ninety nine , eight thousand one hundred , eight thousand one hundred one , eight thousand one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>thousand one hundred twenty four , eight thousand one hundred twenty five , eight thousand one hundred twenty six , eight thousand one hundred twenty seven , eight thousand one hundred twenty eight , eight thousand one hundred twenty nine , eight thousand one hundred thirty , eight thousand one hundred thirty one , eight thousand one hundred thirty two , eight thousand one hundred thirty three , eight thousand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>three , eight thousand one hundred fifty four , eight thousand one hundred fifty five , eight thousand one hundred fifty six , eight thousand one hundred fifty seven , eight thousand one hundred fifty eight , eight thousand one hundred fifty nine , eight thousand one hundred sixty , eight thousand one hundred sixty one , eight thousand one hundred sixty two , eight thousand one hundred sixty three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>thousand one hundred eighty three , eight thousand one hundred eighty four , eight thousand one hundred eighty five , eight thousand one hundred eighty six , eight thousand one hundred eighty seven , eight thousand one hundred eighty eight , eight thousand one hundred eighty nine , eight thousand one hundred ninety , eight thousand one hundred ninety one , eight thousand one hundred ninety two , eight thousand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# showing batch\n",
    "data.show_batch(ds_type=DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Fully Connected Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = src.databunch(bs=int(bs), bptt=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 3]), torch.Size([64, 3]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting one batch and checking the shape\n",
    "x,y = data.one_batch()\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nv = len(v.itos); nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss4(input, target):\n",
    "    return F.cross_entropy(input, target[:,-1])\n",
    "\n",
    "def acc4(input, target):\n",
    "    return accuracy(input, target[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13,  9, 14])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one line - contains three tokens\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'two , three'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.textify(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our input is x\n",
    "# our target is y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer names:\n",
    "\n",
    "* ```i_h```: input to hidden\n",
    "* ```h_h```: hidden to hidden\n",
    "* ```h_o```: hidden to output\n",
    "* ```bn```: batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our model\n",
    "class Model0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.i_h = nn.Embedding(nv, nh) # nv vocab length = , nh = embedding size\n",
    "        self.h_h = nn.Linear(nh, nh)\n",
    "        self.h_o = nn.Linear(nh, nv)\n",
    "        self.bn = nn.BatchNorm1d(nh)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        This forward is designed to be fixed for 3 timesteps, in general you will want to actually use a for loop when 'unrolling' the RNN\n",
    "        \"\"\"\n",
    "        h = self.bn(F.relu(self.i_h(x[:,0])))\n",
    "        \n",
    "        if x.shape[1] > 1:\n",
    "            h = h + self.i_h(x[:,1])\n",
    "            h = self.bn(F.relu(self.h_h(h)))\n",
    "        if x.shape[1] > 2:\n",
    "            h = h + self.i_h(x[:,2])\n",
    "            h = self.bn(F.relu(self.h_h(h)))\n",
    "            \n",
    "        return self.h_o(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13, 13, 10,  9, 18,  9, 11, 11, 13, 19, 16, 23, 24,  9, 12,  9, 13, 14,\n",
       "        15, 11, 10, 22, 15,  9, 10, 14, 11, 16, 10, 28, 11,  9, 20,  9, 15, 15,\n",
       "        11, 18, 10, 28, 23, 24,  9, 16, 10, 16, 19, 20, 12, 10, 22, 16, 17, 17,\n",
       "        17, 11, 24, 10,  9, 15, 16,  9, 18, 11])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call ```x[:,0]``` we are essentially saying feed me an every row in column 1. We will only reach up to ```x[:,2]``` because we only have **3** tokens per line, which is equal to ```bptt``` which is back-propogation-through-time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical Layer of NN\n",
    "By looking at our model above you will see:\n",
    "```python\n",
    "h = self.bn(F.relu(self.i_h(x[0])))\n",
    "```\n",
    "The basic unit of a neural network, which is a single layer of the neural network is compsoed of: \n",
    "\n",
    "* ```batch_norm``` : normalizes activations in that specific layer so they don't explode or vanish\n",
    "* ```relu```: Non-linear activation function. This is usually a ```relu``` in the first layer and hidden layer, but a ```softmax``` in the final layer. \n",
    "* ```Linear```: A linear, Affine function on ``[X @ WT + B]``:\n",
    "    * ```X```: Our raw inputs (normalized in some form)\n",
    "    * ```WT```: Weights, transposed\n",
    "    * ```B```: Bias vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our model object\n",
    "learn = Learner(data, Model0(), loss_func=loss4, metrics=acc4).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mLearner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfastai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataBunch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mopt_func\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mCallable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;32mclass\u001b[0m \u001b[1;34m'torch.optim.adam.Adam'\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.99\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mloss_func\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mCallable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmetrics\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mCollection\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtrue_wd\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbn_wd\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mwd\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCollection\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtrain_bn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpath\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmodel_dir\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'models'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcallback_fns\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mCollection\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mCollection\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfastai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCallback\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mfactory\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlayer_groups\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mCollection\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0madd_time\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msilent\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m      Trainer for `model` using `data` to minimize `loss_func` with optimizer `opt_func`.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\dmber\\anaconda3\\lib\\site-packages\\fastai\\basic_train.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     RNNLearner\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training our model\n",
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 3e-2\n",
    "# lr\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:19 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>acc4</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.595237</td>\n",
       "      <td>3.630497</td>\n",
       "      <td>0.074908</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.014391</td>\n",
       "      <td>3.252281</td>\n",
       "      <td>0.397978</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.451855</td>\n",
       "      <td>2.801948</td>\n",
       "      <td>0.448070</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.150459</td>\n",
       "      <td>2.522917</td>\n",
       "      <td>0.454733</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.030903</td>\n",
       "      <td>2.413841</td>\n",
       "      <td>0.458869</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.005968</td>\n",
       "      <td>2.397740</td>\n",
       "      <td>0.458869</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(6, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model1 With Loop\n",
    "Now we are going to build the same model but with a loop to make it easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce RTX 2070 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.i_h = nn.Embedding(nv, nh) # takes in input sequence of size vocab length, outputs embedding/feature vector\n",
    "        self.h_h = nn.Linear(nh, nh) # takes embedded feature vector, outputs activations\n",
    "        self.h_o = nn.Linear(nh, nv) # takes normalized activations and returns back the output sequence of size vocab length\n",
    "        self.bn = nn.BatchNorm1d(nh) # takes in activation which is of size nh = embedding size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # initializing\n",
    "        # x.shape[0] is the batch size - number of sentences\n",
    "        h = torch.zeros(x.shape[0], nh).to(device=x.device) \n",
    "        \n",
    "        # unrolling\n",
    "        # x.shape[1] is the number of lines in that sentence\n",
    "        for i in range(x.shape[1]):\n",
    "            h = h + self.i_h(x[:, i])\n",
    "            h = self.bn(F.relu(self.h_h(h)))\n",
    "        return self.h_o(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x.shape[0] = size of the batch = how many lines\n",
    "# x.shape[1] = size of the sequence = how many words in the line\n",
    "# nh = the embedding size = number of numerical real values to represent a given word\n",
    "    # 'hello' = [0.2, 3, 1.3, ... , 0.3]\n",
    "x.shape[0], nh, x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x[:, i] - give me all the words in the first column\n",
    "# This will produce a vector of size: (batch_size, nh)\n",
    "    # batch_size = x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(x.shape[0], nh).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(x.shape[0], nh).to(device=x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our second learner\n",
    "learn = Learner(data, Model1(), loss_func=loss4, metrics=acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model1(\n",
       "  (i_h): Embedding(40, 64)\n",
       "  (h_h): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (h_o): Linear(in_features=64, out_features=40, bias=True)\n",
       "  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:15 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>acc4</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.616723</td>\n",
       "      <td>3.621270</td>\n",
       "      <td>0.039292</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.033068</td>\n",
       "      <td>3.040188</td>\n",
       "      <td>0.415901</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.417100</td>\n",
       "      <td>2.501141</td>\n",
       "      <td>0.455423</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.089819</td>\n",
       "      <td>2.261344</td>\n",
       "      <td>0.464844</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.967350</td>\n",
       "      <td>2.185948</td>\n",
       "      <td>0.465763</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.942357</td>\n",
       "      <td>2.176027</td>\n",
       "      <td>0.465763</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(6, 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi fully connected model\n",
    "Before, we were just predicting the last word in a line of text. Given 70 tokens, what is token 71? That approach was throwing away a lot of data. Why not predict token 2 from token 1, then predict token 3, then predict token 4, and so on? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing our time-step to 20\n",
    "data = src.databunch(bs=int(bs), bptt=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 20]), torch.Size([64, 20]))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = data.one_batch()\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So again, in this case the batch size is **64** and the timesteps which was defined with **back-propogration-through-time** is now **20**\n",
    "\n",
    "for this model we are not changing the complexity of the network (increasing the size in depth or width), we are simply just adding more data into our input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.i_h = nn.Embedding(nv, nh)\n",
    "        self.h_h = nn.Linear(nh, nh)\n",
    "        self.h_o = nn.Linear(nh, nv)\n",
    "        self.bn = nn.BatchNorm1d(nh)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # initial hidden\n",
    "        h = torch.zeros(x.shape[0], nh).to(device=device)\n",
    "        \n",
    "        # keeping track of results at each state\n",
    "        res = []\n",
    "        \n",
    "        # forward \n",
    "        for i in range(x.shape[1]):\n",
    "            h = h + self.i_h(x[:,i])\n",
    "            h = F.relu(self.h_h(h))\n",
    "            res.append(self.h_o(self.bn(h)))\n",
    "        \n",
    "        return torch.stack(res, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, Model2(), metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:17 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.703450</td>\n",
       "      <td>3.705074</td>\n",
       "      <td>0.024290</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.616543</td>\n",
       "      <td>3.604595</td>\n",
       "      <td>0.063352</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.509150</td>\n",
       "      <td>3.504478</td>\n",
       "      <td>0.163423</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.397028</td>\n",
       "      <td>3.412466</td>\n",
       "      <td>0.276918</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.290816</td>\n",
       "      <td>3.335292</td>\n",
       "      <td>0.325923</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.198787</td>\n",
       "      <td>3.277302</td>\n",
       "      <td>0.338281</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.126806</td>\n",
       "      <td>3.239194</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.076252</td>\n",
       "      <td>3.218533</td>\n",
       "      <td>0.349858</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.045120</td>\n",
       "      <td>3.210635</td>\n",
       "      <td>0.351776</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.028868</td>\n",
       "      <td>3.209463</td>\n",
       "      <td>0.351918</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 1e-4, pct_start=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy is worse now, because we are doing a harder task. When we predict word k (k<70), we have less history to help us then when we were only prediction word 71. \n",
    "\n",
    "The solution to this is to **save our history**. As you may have noticed in our forward function, we always re-initiate ```h```. \n",
    "\n",
    "To address this issue, let's keep the hidden state from the previous line of text, so wea re not starting over again on each line of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model3(nn.Module):\n",
    "    \"\"\"\n",
    "    This model is now keeping track of all hidden states after every sentence, which will in fact increase the accuracy of the model\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.i_h = nn.Embedding(nv, nh)\n",
    "        self.h_h = nn.Linear(nh, nh)\n",
    "        self.h_o = nn.Linear(nh, nv)\n",
    "        self.bn = nn.BatchNorm1d(nh)\n",
    "        self.h = torch.zeros(bs, nh, dtype=torch.half).cuda() \n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = [] # outputs\n",
    "        h = self.h # hidden state\n",
    "        \n",
    "        for i in range(x.shape[1]):\n",
    "            h = h + self.i_h(x[:,i])\n",
    "            h = F.relu(self.h_h(h))\n",
    "            res.append(self.bn(h))\n",
    "            \n",
    "        self.h = h.detach() # avoids keeping copy\n",
    "        res = torch.stack(res, dim=1) # concatenates sequence of tensors\n",
    "        res = self.h_o(res)\n",
    "        \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, Model3(), metrics=accuracy).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:31 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.549835</td>\n",
       "      <td>3.540303</td>\n",
       "      <td>0.106676</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.211059</td>\n",
       "      <td>2.925416</td>\n",
       "      <td>0.398864</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.564418</td>\n",
       "      <td>2.016008</td>\n",
       "      <td>0.461009</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.993452</td>\n",
       "      <td>1.946665</td>\n",
       "      <td>0.318963</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.697688</td>\n",
       "      <td>1.957172</td>\n",
       "      <td>0.328835</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.522820</td>\n",
       "      <td>1.776082</td>\n",
       "      <td>0.471946</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.387139</td>\n",
       "      <td>1.694529</td>\n",
       "      <td>0.521449</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.245820</td>\n",
       "      <td>1.578009</td>\n",
       "      <td>0.552202</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.089744</td>\n",
       "      <td>1.524006</td>\n",
       "      <td>0.578764</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.953259</td>\n",
       "      <td>1.515239</td>\n",
       "      <td>0.584375</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.836230</td>\n",
       "      <td>1.510860</td>\n",
       "      <td>0.594389</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.738797</td>\n",
       "      <td>1.506742</td>\n",
       "      <td>0.601278</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.658789</td>\n",
       "      <td>1.449290</td>\n",
       "      <td>0.618537</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.595728</td>\n",
       "      <td>1.460561</td>\n",
       "      <td>0.615980</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.546747</td>\n",
       "      <td>1.364570</td>\n",
       "      <td>0.644034</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.510010</td>\n",
       "      <td>1.390258</td>\n",
       "      <td>0.634517</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.481058</td>\n",
       "      <td>1.398106</td>\n",
       "      <td>0.637571</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.460315</td>\n",
       "      <td>1.399600</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.447205</td>\n",
       "      <td>1.399513</td>\n",
       "      <td>0.640128</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.440364</td>\n",
       "      <td>1.406211</td>\n",
       "      <td>0.637145</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(20, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.RNN\n",
    "Let's now refactor all the code above to use PyTorch's RNN. This is what you would use in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 64)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nv, nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.i_h = nn.Embedding(nv, nh)\n",
    "        self.rnn = nn.RNN(nh, nh, batch_first=True) \n",
    "        self.h_o = nn.Linear(nh, nv)\n",
    "        self.bn = BatchNorm1dFlat(nh)\n",
    "        self.h = torch.zeros(1, bs, nh, dtype=torch.half).cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res, h = self.rnn(self.i_h(x), self.h)\n",
    "        self.h = h.detach()\n",
    "        return self.h_o(self.bn(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mBatchNorm1dFlat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnum_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-05\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0maffine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtrack_running_stats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m        \n",
       "\u001b[1;32mclass\u001b[0m \u001b[0mBatchNorm1dFlat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchNorm1d\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34m\"`nn.BatchNorm1d`, but first flattens leading dimensions\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;33m*\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\dmber\\anaconda3\\lib\\site-packages\\fastai\\layers.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??BatchNorm1dFlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, Model4(), metrics=accuracy).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:10 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.565941</td>\n",
       "      <td>3.499253</td>\n",
       "      <td>0.084730</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.094652</td>\n",
       "      <td>2.632511</td>\n",
       "      <td>0.450213</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.385264</td>\n",
       "      <td>1.914898</td>\n",
       "      <td>0.406960</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.889531</td>\n",
       "      <td>1.957727</td>\n",
       "      <td>0.331676</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.609220</td>\n",
       "      <td>1.765874</td>\n",
       "      <td>0.471591</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.372195</td>\n",
       "      <td>1.593361</td>\n",
       "      <td>0.503551</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.149054</td>\n",
       "      <td>1.578473</td>\n",
       "      <td>0.533239</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.965053</td>\n",
       "      <td>1.507169</td>\n",
       "      <td>0.561506</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.816868</td>\n",
       "      <td>1.363181</td>\n",
       "      <td>0.600781</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.709663</td>\n",
       "      <td>1.390668</td>\n",
       "      <td>0.606960</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.621867</td>\n",
       "      <td>1.416186</td>\n",
       "      <td>0.614560</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.548288</td>\n",
       "      <td>1.430590</td>\n",
       "      <td>0.623153</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.489922</td>\n",
       "      <td>1.460605</td>\n",
       "      <td>0.621378</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.444763</td>\n",
       "      <td>1.401480</td>\n",
       "      <td>0.637145</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.407120</td>\n",
       "      <td>1.394327</td>\n",
       "      <td>0.645028</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.376855</td>\n",
       "      <td>1.347170</td>\n",
       "      <td>0.653125</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.354501</td>\n",
       "      <td>1.348149</td>\n",
       "      <td>0.654759</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.337889</td>\n",
       "      <td>1.338302</td>\n",
       "      <td>0.666903</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.325959</td>\n",
       "      <td>1.352789</td>\n",
       "      <td>0.662003</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.318657</td>\n",
       "      <td>1.369453</td>\n",
       "      <td>0.659020</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(20, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-layer GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.i_h = nn.Embedding(nv, nh)\n",
    "        self.rnn = nn.GRU(nh, nh, 2, batch_first=True)\n",
    "        self.h_o = nn.Linear(nh, nv)\n",
    "        self.bn = BatchNorm1dFlat(nh)\n",
    "        self.h = torch.zeros(2, bs, nh, dtype=torch.half).cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res, h = self.rnn(self.i_h(x), self.h)\n",
    "        self.h = h.detach()\n",
    "        return self.h_o(self.bn(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, Model5(), metrics=accuracy).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:07 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.960606</td>\n",
       "      <td>2.324086</td>\n",
       "      <td>0.452770</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.853075</td>\n",
       "      <td>1.473501</td>\n",
       "      <td>0.594460</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.958746</td>\n",
       "      <td>1.042163</td>\n",
       "      <td>0.798011</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.465310</td>\n",
       "      <td>0.924009</td>\n",
       "      <td>0.836151</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.231529</td>\n",
       "      <td>0.978605</td>\n",
       "      <td>0.838210</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.120420</td>\n",
       "      <td>0.944951</td>\n",
       "      <td>0.840696</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.066706</td>\n",
       "      <td>0.971845</td>\n",
       "      <td>0.839276</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.039122</td>\n",
       "      <td>1.004930</td>\n",
       "      <td>0.835867</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.024751</td>\n",
       "      <td>1.027974</td>\n",
       "      <td>0.831960</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.017318</td>\n",
       "      <td>1.014146</td>\n",
       "      <td>0.833026</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connected to ULMFiT \n",
    "In the previous notebook, we were essentially swapping out ```self.h_o``` with a classifier in order to do classification on text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
