{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Translation - LINUX\n",
    "*LINUX - the previous notebooks have all been ran on a Windows OS laptop containing a RTX2070-MaxQ Graphics card. For this specific notebook & the next, we will be using a Linux machine hosted via Paperspace. The reason for the switch is mainly due to fastText not having supporting binaries for Windows OS.*\n",
    "\n",
    "Im this notebook we will be tackling the task of translation. We will be translating French to English - specifically translating quesitons. \n",
    "\n",
    "This task is an example of Sequence to Sequence (seq2seq). Seq2Seq can be more challenging than classification, since the output is of variable length (different from the length of the input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and preprocess our data\n",
    "We will begin by reducing the original dataset to questions. You only need to execute this once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Config().data_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading the data\n",
    "# !wget https://s3.amazonaws.com/fast-ai-nlp/giga-fren.tgz -P {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/dmber/.fastai/data/giga-fren.tgz'),\n",
       " WindowsPath('C:/Users/dmber/.fastai/data/human_numbers'),\n",
       " WindowsPath('C:/Users/dmber/.fastai/data/human_numbers.tgz'),\n",
       " WindowsPath('C:/Users/dmber/.fastai/data/imdb.tgz'),\n",
       " WindowsPath('C:/Users/dmber/.fastai/data/imdb_sample.tgz')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar xf {path}/giga-fren.tgz -C {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/dmber/.fastai/data/giga-fren'),\n",
       " WindowsPath('C:/Users/dmber/.fastai/data/giga-fren.tgz'),\n",
       " WindowsPath('C:/Users/dmber/.fastai/data/human_numbers'),\n",
       " WindowsPath('C:/Users/dmber/.fastai/data/human_numbers.tgz'),\n",
       " WindowsPath('C:/Users/dmber/.fastai/data/imdb.tgz'),\n",
       " WindowsPath('C:/Users/dmber/.fastai/data/imdb_sample.tgz')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/dmber/.fastai/data/giga-fren/giga-fren.release2.fixed.en'),\n",
       " WindowsPath('C:/Users/dmber/.fastai/data/giga-fren/giga-fren.release2.fixed.fr')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Config().data_path()/'giga-fren'\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re_eq = re.compile('^(Wh[^?.!]+\\?)')\n",
    "# re_fq = re.compile('^([^?.!]+\\?)')\n",
    "# en_fname = path/'giga-fren.release2.fixed.en'\n",
    "# fr_fname = path/'giga-fren.release2.fixed.fr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = ((re_eq.search(eq), re_fq.search(fq)) \n",
    "#         for eq, fq in zip(open(en_fname, encoding='utf-8'), open(fr_fname, encoding='utf-8')))\n",
    "# qs = [(e.group(), f.group()) for e,f in lines if e and f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qs = [(q1,q2) for q1,q2 in qs]\n",
    "# df = pd.DataFrame({'fr': [q[1] for q in qs], 'en': [q[0] for q in qs]}, columns = ['en', 'fr'])\n",
    "# df.to_csv(path/'questions_easy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/dmber/.fastai/data/giga-fren/giga-fren.release2.fixed.en'),\n",
       " WindowsPath('C:/Users/dmber/.fastai/data/giga-fren/giga-fren.release2.fixed.fr'),\n",
       " WindowsPath('C:/Users/dmber/.fastai/data/giga-fren/questions_easy.csv')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our data into a DataBunch\n",
    "What do our questions look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is light ?</td>\n",
       "      <td>Qu’est-ce que la lumière?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who are we?</td>\n",
       "      <td>Où sommes-nous?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Where did we come from?</td>\n",
       "      <td>D'où venons-nous?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What would we do without it?</td>\n",
       "      <td>Que ferions-nous sans elle ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the absolute location (latitude and lo...</td>\n",
       "      <td>Quelle sont les coordonnées (latitude et longi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0                                    What is light ?   \n",
       "1                                        Who are we?   \n",
       "2                            Where did we come from?   \n",
       "3                       What would we do without it?   \n",
       "4  What is the absolute location (latitude and lo...   \n",
       "\n",
       "                                                  fr  \n",
       "0                          Qu’est-ce que la lumière?  \n",
       "1                                    Où sommes-nous?  \n",
       "2                                  D'où venons-nous?  \n",
       "3                       Que ferions-nous sans elle ?  \n",
       "4  Quelle sont les coordonnées (latitude et longi...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'questions_easy.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52331 entries, 0 to 52330\n",
      "Data columns (total 2 columns):\n",
      "en    52331 non-null object\n",
      "fr    52331 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 817.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is light ?</td>\n",
       "      <td>qu’est-ce que la lumière?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>who are we?</td>\n",
       "      <td>où sommes-nous?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>where did we come from?</td>\n",
       "      <td>d'où venons-nous?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what would we do without it?</td>\n",
       "      <td>que ferions-nous sans elle ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the absolute location (latitude and lo...</td>\n",
       "      <td>quelle sont les coordonnées (latitude et longi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0                                    what is light ?   \n",
       "1                                        who are we?   \n",
       "2                            where did we come from?   \n",
       "3                       what would we do without it?   \n",
       "4  what is the absolute location (latitude and lo...   \n",
       "\n",
       "                                                  fr  \n",
       "0                          qu’est-ce que la lumière?  \n",
       "1                                    où sommes-nous?  \n",
       "2                                  d'où venons-nous?  \n",
       "3                       que ferions-nous sans elle ?  \n",
       "4  quelle sont les coordonnées (latitude et longi...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowercasing everything to make it simple\n",
    "df['en'] = df['en'].apply(lambda x:x.lower())\n",
    "df['fr'] = df['fr'].apply(lambda x:x.lower())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collate\n",
    "Given that our input and outputs are of different lengths, we must collate inputs and targets in a batch. That is adding 0 padding. \n",
    "\n",
    "This will create all sequences have the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_collate(samples, pad_idx=1, pad_first=True, backwards=False):\n",
    "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
    "    samples = to_data(samples)\n",
    "    max_len_x,max_len_y = max([len(s[0]) for s in samples]),max([len(s[1]) for s in samples])\n",
    "    res_x = torch.zeros(len(samples), max_len_x).long() + pad_idx\n",
    "    res_y = torch.zeros(len(samples), max_len_y).long() + pad_idx\n",
    "    if backwards: pad_first = not pad_first\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: \n",
    "            res_x[i,-len(s[0]):],res_y[i,-len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
    "        else:         \n",
    "            res_x[i,:len(s[0]):],res_y[i,:len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
    "    if backwards: res_x,res_y = res_x.flip(1),res_y.flip(1)\n",
    "    return res_x,res_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4 id=\"to_data\" class=\"doc_header\"><code>to_data</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L104\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#to_data-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4><blockquote><p><code>to_data</code>(<strong><code>b</code></strong>:<code>ItemsList</code>)</p>\n",
       "</blockquote>\n",
       "<div class=\"collapse\" id=\"to_data-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#to_data-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>Tests found for <code>to_data</code>:</p><ul><li><code>pytest -sv tests/test_torch_core.py::test_to_data</code> <a href=\"https://github.com/fastai/fastai/blob/master/tests/test_torch_core.py#L106\" class=\"source_link\" style=\"float:right\">[source]</a></li></ul><p>To run tests please refer to this <a href=\"/dev/test.html#quick-guide\">guide</a>.</p></div></div><p>Recursively map lists of items in <code>b</code> to their wrapped data.</p>\n",
       "<p><a href=\"https://docs.fast.ai/torch_core.html#to_data\" target=\"_blank\" rel=\"noreferrer noopener\">Show in docs</a></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc(to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2 id=\"Dataset\" class=\"doc_header\"><code>class</code> <code>Dataset</code><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#Dataset-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h2><blockquote><p><code>Dataset</code>()</p>\n",
       "</blockquote>\n",
       "<div class=\"collapse\" id=\"Dataset-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#Dataset-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>Dataset</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div><p>An abstract class representing a Dataset. All other datasets should subclass it. All subclasses should override\n",
       "<code>__len__</code>, that provides the size of the dataset, and <code>__getitem__</code>,\n",
       "supporting integer indexing in range from 0 to len(self) exclusive.</p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc(Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ```Dataset```\n",
    "Is essentially the main class that will store datasets. Any datasets created under this class will essentially be a subclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2 id=\"DataLoader\" class=\"doc_header\"><code>class</code> <code>DataLoader</code><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#DataLoader-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h2><blockquote><p><code>DataLoader</code>(<strong><code>dataset</code></strong>, <strong><code>batch_size</code></strong>=<strong><em><code>1</code></em></strong>, <strong><code>shuffle</code></strong>=<strong><em><code>False</code></em></strong>, <strong><code>sampler</code></strong>=<strong><em><code>None</code></em></strong>, <strong><code>batch_sampler</code></strong>=<strong><em><code>None</code></em></strong>, <strong><code>num_workers</code></strong>=<strong><em><code>0</code></em></strong>, <strong><code>collate_fn</code></strong>=<strong><em><code>'default_collate'</code></em></strong>, <strong><code>pin_memory</code></strong>=<strong><em><code>True</code></em></strong>, <strong><code>drop_last</code></strong>=<strong><em><code>False</code></em></strong>, <strong><code>timeout</code></strong>=<strong><em><code>0</code></em></strong>, <strong><code>worker_init_fn</code></strong>=<strong><em><code>None</code></em></strong>)</p>\n",
       "</blockquote>\n",
       "<div class=\"collapse\" id=\"DataLoader-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#DataLoader-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>DataLoader</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div><p>Data loader. Combines a dataset and a sampler, and provides single- or multi-process iterators over the dataset.</p>\n",
       "<p>Arguments:\n",
       "    dataset (Dataset): dataset from which to load the data.\n",
       "    batch_size (int, optional): how many samples per batch to load\n",
       "        (default: <code>1</code>).\n",
       "    shuffle (bool, optional): set to <code>True</code> to have the data reshuffled\n",
       "        at every epoch (default: <code>False</code>).\n",
       "    sampler (Sampler, optional): defines the strategy to draw samples from\n",
       "        the dataset. If specified, <code>shuffle</code> must be False.\n",
       "    batch_sampler (Sampler, optional): like sampler, but returns a batch of\n",
       "        indices at a time. Mutually exclusive with :attr:<code>batch_size</code>,\n",
       "        :attr:<code>shuffle</code>, :attr:<code>sampler</code>, and :attr:<code>drop_last</code>.\n",
       "    num_workers (int, optional): how many subprocesses to use for data\n",
       "        loading. 0 means that the data will be loaded in the main process.\n",
       "        (default: <code>0</code>)\n",
       "    collate_fn (callable, optional): merges a list of samples to form a mini-batch.\n",
       "    pin_memory (bool, optional): If <code>True</code>, the data loader will copy tensors\n",
       "        into CUDA pinned memory before returning them.  If your data elements\n",
       "        are a custom type, or your <code>collate_fn</code> returns a batch that is a custom type\n",
       "        see the example below.\n",
       "    drop_last (bool, optional): set to <code>True</code> to drop the last incomplete batch,\n",
       "        if the dataset size is not divisible by the batch size. If <code>False</code> and\n",
       "        the size of dataset is not divisible by the batch size, then the last batch\n",
       "        will be smaller. (default: <code>False</code>)\n",
       "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
       "        from workers. Should always be non-negative. (default: <code>0</code>)\n",
       "    worker_init_fn (callable, optional): If not <code>None</code>, this will be called on each\n",
       "        worker subprocess with the worker id (an int in <code>[0, num_workers - 1]</code>) as\n",
       "        input, after seeding and before data loading. (default: <code>None</code>)</p>\n",
       "<p>.. note:: When <code>num_workers != 0</code>, the corresponding worker processes are created each time\n",
       "          iterator for the DataLoader is obtained (as in when you call\n",
       "          <code>enumerate(dataloader,0)</code>).\n",
       "          At this point, the dataset, <code>collate_fn</code> and <code>worker_init_fn</code> are passed to each\n",
       "          worker, where they are used to access and initialize data based on the indices\n",
       "          queued up from the main process. This means that dataset access together with\n",
       "          its internal IO, transforms and collation runs in the worker, while any\n",
       "          shuffle randomization is done in the main process which guides loading by assigning\n",
       "          indices to load. Workers are shut down once the end of the iteration is reached.</p>\n",
       "\n",
       "<pre><code>      Since workers rely on Python multiprocessing, worker launch behavior is different\n",
       "      on Windows compared to Unix. On Unix fork() is used as the default\n",
       "      muliprocessing start method, so child workers typically can access the dataset and\n",
       "      Python argument functions directly through the cloned address space. On Windows, another\n",
       "      interpreter is launched which runs your main script, followed by the internal\n",
       "      worker function that receives the dataset, collate_fn and other arguments\n",
       "      through Pickle serialization.\n",
       "\n",
       "      This separate serialization means that you should take two steps to ensure you\n",
       "      are compatible with Windows while using workers\n",
       "      (this also works equally well on Unix):\n",
       "\n",
       "      - Wrap most of you main script's code within ``if __name__ == '__main__':`` block,\n",
       "        to make sure it doesn't run again (most likely generating error) when each worker\n",
       "        process is launched. You can place your dataset and DataLoader instance creation\n",
       "        logic here, as it doesn't need to be re-executed in workers.\n",
       "      - Make sure that ``collate_fn``, ``worker_init_fn`` or any custom dataset code\n",
       "        is declared as a top level def, outside of that ``__main__`` check. This ensures\n",
       "        they are available in workers as well\n",
       "        (this is needed since functions are pickled as references only, not bytecode).\n",
       "\n",
       "      By default, each worker will have its PyTorch seed set to\n",
       "      ``base_seed + worker_id``, where ``base_seed`` is a long generated\n",
       "      by main process using its RNG. However, seeds for other libraies\n",
       "      may be duplicated upon initializing workers (w.g., NumPy), causing\n",
       "      each worker to return identical random numbers. (See\n",
       "      :ref:`dataloader-workers-random-seed` section in FAQ.) You may\n",
       "      use :func:`torch.initial_seed()` to access the PyTorch seed for\n",
       "      each worker in :attr:`worker_init_fn`, and use it to set other\n",
       "      seeds before data loading.\n",
       "\n",
       "</code></pre>\n",
       "<p>.. warning:: If <code>spawn</code> start method is used, :attr:<code>worker_init_fn</code> cannot be an\n",
       "             unpicklable object, e.g., a lambda function.</p>\n",
       "<p>The default memory pinning logic only recognizes Tensors and maps and iterables\n",
       "containg Tensors.  By default, if the pinning logic sees a batch that is a custom type\n",
       "(which will occur if you have a <code>collate_fn</code> that returns a custom batch type),\n",
       "or if each element of your batch is a custom type, the pinning logic will not\n",
       "recognize them, and it will return that batch (or those elements)\n",
       "without pinning the memory.  To enable memory pinning for custom batch or data types,\n",
       "define a <code>pin_memory</code> method on your custom type(s).</p>\n",
       "<p>Example::</p>\n",
       "\n",
       "<pre><code>class SimpleCustomBatch:\n",
       "    def __init__(self, data):\n",
       "        transposed_data = list(zip(*data))\n",
       "        self.inp = torch.stack(transposed_data[0], 0)\n",
       "        self.tgt = torch.stack(transposed_data[1], 0)\n",
       "\n",
       "    def pin_memory(self):\n",
       "        self.inp = self.inp.pin_memory()\n",
       "        self.tgt = self.tgt.pin_memory()\n",
       "        return self\n",
       "\n",
       "def collate_wrapper(batch):\n",
       "    return SimpleCustomBatch(batch)\n",
       "\n",
       "inps = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)\n",
       "tgts = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)\n",
       "dataset = TensorDataset(inps, tgts)\n",
       "\n",
       "loader = DataLoader(dataset, batch_size=2, collate_fn=collate_wrapper,\n",
       "                    pin_memory=True)\n",
       "\n",
       "for batch_ndx, sample in enumerate(loader):\n",
       "    print(sample.inp.is_pinned())\n",
       "    print(sample.tgt.is_pinned()) </code></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_dl, valid_dl are all of DataLoader types\n",
    "doc(DataLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ```DataLoader```\n",
    "This gives us a way to iterate over a dataset. Therefor we must first create the ```dataset``` and them create ```dataloaders```. \n",
    "\n",
    "DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn='default_collate', pin_memory=True, drop_last=False, timeout=0, worker_init_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2 id=\"DataBunch\" class=\"doc_header\"><code>class</code> <code>DataBunch</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/basic_data.py#L84\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#DataBunch-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h2><blockquote><p><code>DataBunch</code>(<strong><code>train_dl</code></strong>:<a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\"><code>DataLoader</code></a>, <strong><code>valid_dl</code></strong>:<a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\"><code>DataLoader</code></a>, <strong><code>fix_dl</code></strong>:<a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\"><code>DataLoader</code></a>=<strong><em><code>None</code></em></strong>, <strong><code>test_dl</code></strong>:<code>Optional</code>[<a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\"><code>DataLoader</code></a>]=<strong><em><code>None</code></em></strong>, <strong><code>device</code></strong>:<a href=\"https://pytorch.org/docs/stable/tensor_attributes.html#torch-device\"><code>device</code></a>=<strong><em><code>None</code></em></strong>, <strong><code>dl_tfms</code></strong>:<code>Optional</code>[<code>Collection</code>[<code>Callable</code>]]=<strong><em><code>None</code></em></strong>, <strong><code>path</code></strong>:<code>PathOrStr</code>=<strong><em><code>'.'</code></em></strong>, <strong><code>collate_fn</code></strong>:<code>Callable</code>=<strong><em><code>'data_collate'</code></em></strong>, <strong><code>no_check</code></strong>:<code>bool</code>=<strong><em><code>False</code></em></strong>)</p>\n",
       "</blockquote>\n",
       "<div class=\"collapse\" id=\"DataBunch-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#DataBunch-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>Tests found for <code>DataBunch</code>:</p><ul><li><code>pytest -sv tests/test_data_block.py::test_custom_dataset</code> <a href=\"https://github.com/fastai/fastai/blob/master/tests/test_data_block.py#L143\" class=\"source_link\" style=\"float:right\">[source]</a></li></ul><p>To run tests please refer to this <a href=\"/dev/test.html#quick-guide\">guide</a>.</p></div></div><p>Bind <code>train_dl</code>,<code>valid_dl</code> and <code>test_dl</code> in a data object.</p>\n",
       "<p><a href=\"https://docs.fast.ai/basic_data.html#DataBunch\" target=\"_blank\" rel=\"noreferrer noopener\">Show in docs</a></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc(DataBunch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ```DataBunch```\n",
    "This essentially puts it all together hence it is always called last when creating a dataset with FasAI.\n",
    "\n",
    "This will combine all your dataloaders into a single object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our own TextDataBunch\n",
    "class Seq2SeqDataBunch(TextDataBunch):\n",
    "    \"Create a `TextDataBunch` suitable for training an RNN classifier.\"\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=32, val_bs:int=None, pad_idx=1,\n",
    "               dl_tfms=None, pad_first=False, device:torch.device=None, no_check:bool=False, backwards:bool=False, **dl_kwargs) -> DataBunch:\n",
    "        \"Function that transform the `datasets` in a `DataBunch` for classification. Passes `**dl_kwargs` on to `DataLoader()`\"\n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        collate_fn = partial(seq2seq_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
    "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
    "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
    "        dataloaders = [train_dl]\n",
    "        for ds in datasets[1:]:\n",
    "            lengths = [len(t) for t in ds.x.items]\n",
    "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
    "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
    "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSource:\u001b[0m\n",
       "    \u001b[1;33m@\u001b[0m\u001b[0mline_magic\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;34m\"\"\"Clear the terminal.\"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'posix'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"clear\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cls\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m   c:\\users\\dmber\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cls??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2 id=\"SortishSampler\" class=\"doc_header\"><code>class</code> <code>SortishSampler</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/text/data.py#L107\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#SortishSampler-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h2><blockquote><p><code>SortishSampler</code>(<strong><code>data_source</code></strong>:<code>NPArrayList</code>, <strong><code>key</code></strong>:<code>KeyFunc</code>, <strong><code>bs</code></strong>:<code>int</code>) :: <a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.Sampler\"><code>Sampler</code></a></p>\n",
       "</blockquote>\n",
       "<div class=\"collapse\" id=\"SortishSampler-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#SortishSampler-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>Tests found for <code>SortishSampler</code>:</p><ul><li><code>pytest -sv tests/test_text_data.py::test_sortish_sampler</code> <a href=\"https://github.com/fastai/fastai/blob/master/tests/test_text_data.py#L143\" class=\"source_link\" style=\"float:right\">[source]</a></li></ul><p>To run tests please refer to this <a href=\"/dev/test.html#quick-guide\">guide</a>.</p></div></div><p>Go through the text data by order of length with a bit of randomness.</p>\n",
       "<p><a href=\"https://docs.fast.ai/text.data.html#SortishSampler\" target=\"_blank\" rel=\"noreferrer noopener\">Show in docs</a></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc(SortishSampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a subclass of ```TextList``` tjat will use this ```DataBunch``` class in the call ```.databunch``` and will use ```TextList``` to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTextList(TextList):\n",
    "    _bunch = Seq2SeqDataBunch\n",
    "    _label_cls = TextList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to use the datablock API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Seq2Seq TextList\n",
    "src = Seq2SeqTextList.from_df(df, path=path, cols='fr').split_by_rand_pct(seed=42).label_from_df(cols='en', label_cls=TextList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 28.0, y: 23.0\n"
     ]
    }
   ],
   "source": [
    "# checking the length of both x, y => 90th percentile for each\n",
    "x_per = np.percentile([len(o) for o in src.train.x.items] + [len(o) for o in src.valid.x.items], 90) \n",
    "y_per = np.percentile([len(o) for o in src.train.y.items] + [len(o) for o in src.valid.y.items], 90) \n",
    "print(f'x: {x_per}, y: {y_per}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now remove items where one of the target is more than 30 tokens long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelLists;\n",
       "\n",
       "Train: LabelList (41865 items)\n",
       "x: Seq2SeqTextList\n",
       "xxbos qu’est - ce que la lumière ?,xxbos où sommes - nous ?,xxbos d'où venons - nous ?,xxbos que ferions - nous sans elle ?,xxbos quel est le groupe autochtone principal sur l’île de vancouver ?\n",
       "y: TextList\n",
       "xxbos what is light ?,xxbos who are we ?,xxbos where did we come from ?,xxbos what would we do without it ?,xxbos what is the major aboriginal group on vancouver island ?\n",
       "Path: C:\\Users\\dmber\\.fastai\\data\\giga-fren;\n",
       "\n",
       "Valid: LabelList (10466 items)\n",
       "x: Seq2SeqTextList\n",
       "xxbos quels pourraient être les effets sur l’instrument de xxunk et sur l’aide humanitaire qui ne sont pas co - xxunk ?,xxbos quand la source primaire a - t - elle été créée ?,xxbos pourquoi tant de soldats ont - ils fait xxunk de ne pas voir ce qui s'est passé le 4 et le 16 mars ?,xxbos quels sont les taux d'impôt sur le revenu au canada pour 2007 ?,xxbos pourquoi le programme devrait - il intéresser les employeurs et les fournisseurs de services ?\n",
       "y: TextList\n",
       "xxbos what would be the resulting effects on the pre - accession instrument and humanitarian aid that are not co - decided ?,xxbos when was the primary source created ?,xxbos why did so many soldiers look the other way in relation to the incidents of march 4th and march xxunk ?,xxbos what are the income tax rates in canada for 2007 ?,xxbos why is the program good for employers and service providers ?\n",
       "Path: C:\\Users\\dmber\\.fastai\\data\\giga-fren;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering - removing anythign less then 30 tokens\n",
    "src = src.filter_by_func(lambda x,y: len(x) > 30 or len(y) > 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our databunch\n",
    "data = src.databunch(num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "data.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqDataBunch;\n",
       "\n",
       "Train: LabelList (41865 items)\n",
       "x: Seq2SeqTextList\n",
       "xxbos contenu introduction aux its saviez - vous que … ?,xxbos contenu introduction aux its saviez - vous que … ?,xxbos contenu introduction aux its saviez - vous que … ?,xxbos contenu introduction aux its saviez - vous que … ?,xxbos contenu introduction aux its saviez - vous que … ?\n",
       "y: TextList\n",
       "xxbos what 's inside introduction to xxunk did you know … ?,xxbos what 's inside introduction to xxunk did you know … ?,xxbos what 's inside introduction to xxunk did you know … ?,xxbos what 's inside introduction to xxunk did you know … ?,xxbos what 's inside introduction to xxunk did you know … ?\n",
       "Path: C:\\Users\\dmber\\.fastai\\data\\giga-fren;\n",
       "\n",
       "Valid: LabelList (10466 items)\n",
       "x: Seq2SeqTextList\n",
       "xxbos quand demander une protection à l’étranger ?,xxbos quand demander une protection à l’étranger ?,xxbos quand demander une protection à l’étranger ?,xxbos quand demander une protection à l’étranger ?,xxbos quand demander une protection à l’étranger ?\n",
       "y: TextList\n",
       "xxbos when to apply for protection abroad ?,xxbos when to apply for protection abroad ?,xxbos when to apply for protection abroad ?,xxbos when to apply for protection abroad ?,xxbos when to apply for protection abroad ?\n",
       "Path: C:\\Users\\dmber\\.fastai\\data\\giga-fren;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loading the data if we need to quickly\n",
    "# data = load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52331"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52331"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(src.train) + len(src.valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: On windows, you may have a problem with a databunch object - this in fact a problem with PyTorch & Windows implementation. A workaround is to set the ```num_workers=0```. But if you are now to call ```show_batch()``` on our databunch object, you will notice elements are copied over. \n",
    "\n",
    "It may be smart to do all the data preprocessing on a Linux/Unix machine before working on a Windows. Just save the databunch object and pull it into the later working directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating our Model\n",
    "## PreTrained Embeddings\n",
    "Moving forward we will download the word embeddings (crawl vectors) from the fastText. FastText has pre-trained word vectors for 157 languages, trained on Common Crawl and Wikipedia. These models were trained using CBOW.\n",
    "\n",
    "Learn more about word embeddings here: https://www.youtube.com/watch?v=25nC0n9ERq4&list=PLtmWHNX-gukLQlMvtRJ19s7-8MrnRV6h6&index=10&t=0s\n",
    "\n",
    "To install FastText run the following commands:\n",
    "```\n",
    "$ git clone https://github.com/facebookresearch/fastText.git\n",
    "$ cd fastText\n",
    "$ pip install .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note to self\n",
    "# DELETE giga-fren.tgz\n",
    "# DELETE giga-fren Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
